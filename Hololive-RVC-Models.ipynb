{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aziib/Create-Google-Shared-Drive/blob/master/Hololive-RVC-Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check GPU"
      ],
      "metadata": {
        "id": "kwjWcLtIGP56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "I7XtgrWyGO03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\"GPU üî•\" if torch.cuda.is_available() else \"CPU ü•∂\""
      ],
      "metadata": {
        "id": "re3EAOUUKwL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Hugging Face Spaces Repo"
      ],
      "metadata": {
        "id": "IuJNlXTDFNRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzHQxbDoEHVm"
      },
      "outputs": [],
      "source": [
        "! git clone https://huggingface.co/spaces/megaaziib/hololive-rvc-models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter the Directory that's just downloaded"
      ],
      "metadata": {
        "id": "bq1JLmTwFQS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hololive-rvc-models"
      ],
      "metadata": {
        "id": "ct3VVCUhEXNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the contents of the Directory"
      ],
      "metadata": {
        "id": "GbVA-MeMFSB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "tnrRcfoHFJNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the required libraries"
      ],
      "metadata": {
        "id": "jSwgikZUFXSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "wor-1cibFJ5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q #gradio isn't required to be mentioned on requirements for apps on HF space"
      ],
      "metadata": {
        "id": "t0zsiM0VFMVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "bhaVbdIIMWIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edit the app.py file if required"
      ],
      "metadata": {
        "id": "fcKIzh-UJdeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import argparse\n",
        "import traceback\n",
        "import logging\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import asyncio\n",
        "import edge_tts\n",
        "from datetime import datetime\n",
        "from fairseq import checkpoint_utils\n",
        "from infer_pack.models import SynthesizerTrnMs256NSFsid, SynthesizerTrnMs256NSFsid_nono\n",
        "from vc_infer_pipeline import VC\n",
        "from config import (\n",
        "    is_half,\n",
        "    device\n",
        ")\n",
        "logging.getLogger(\"numba\").setLevel(logging.WARNING)\n",
        "limitation = os.getenv(\"SYSTEM\") == \"spaces\"  # limit audio length in huggingface spaces\n",
        "\n",
        "def create_vc_fn(tgt_sr, net_g, vc, if_f0, file_index, file_big_npy):\n",
        "    def vc_fn(\n",
        "        input_audio,\n",
        "        f0_up_key,\n",
        "        f0_method,\n",
        "        index_rate,\n",
        "        tts_mode,\n",
        "        tts_text,\n",
        "        tts_voice\n",
        "    ):\n",
        "        try:\n",
        "            if tts_mode:\n",
        "                if len(tts_text) > 1200 and limitation:\n",
        "                    return \"Text is too long\", None\n",
        "                if tts_text is None or tts_voice is None:\n",
        "                    return \"You need to enter text and select a voice\", None\n",
        "                asyncio.run(edge_tts.Communicate(tts_text, \"-\".join(tts_voice.split('-')[:-1])).save(\"tts.mp3\"))\n",
        "                audio, sr = librosa.load(\"tts.mp3\", sr=16000, mono=True)\n",
        "            else:\n",
        "                if args.files:\n",
        "                    audio, sr = librosa.load(input_audio, sr=16000, mono=True)\n",
        "                else:\n",
        "                    if input_audio is None:\n",
        "                        return \"You need to upload an audio\", None\n",
        "                    sampling_rate, audio = input_audio\n",
        "                    duration = audio.shape[0] / sampling_rate\n",
        "                    if duration > 660 and limitation:\n",
        "                        return \"Please upload an audio file that is less than 11 minutes.\", None\n",
        "                    audio = (audio / np.iinfo(audio.dtype).max).astype(np.float32)\n",
        "                    if len(audio.shape) > 1:\n",
        "                        audio = librosa.to_mono(audio.transpose(1, 0))\n",
        "                    if sampling_rate != 16000:\n",
        "                        audio = librosa.resample(audio, orig_sr=sampling_rate, target_sr=16000)\n",
        "            times = [0, 0, 0]\n",
        "            f0_up_key = int(f0_up_key)\n",
        "            audio_opt = vc.pipeline(\n",
        "                hubert_model,\n",
        "                net_g,\n",
        "                0,\n",
        "                audio,\n",
        "                times,\n",
        "                f0_up_key,\n",
        "                f0_method,\n",
        "                file_index,\n",
        "                file_big_npy,\n",
        "                index_rate,\n",
        "                if_f0,\n",
        "            )\n",
        "            print(\n",
        "                f\"[{datetime.now().strftime('%Y-%m-%d %H:%M')}]: npy: {times[0]}, f0: {times[1]}s, infer: {times[2]}s\"\n",
        "            )\n",
        "            return \"Success\", (tgt_sr, audio_opt)\n",
        "        except:\n",
        "            info = traceback.format_exc()\n",
        "            print(info)\n",
        "            return info, (None, None)\n",
        "    return vc_fn\n",
        "\n",
        "def load_hubert():\n",
        "    global hubert_model\n",
        "    models, _, _ = checkpoint_utils.load_model_ensemble_and_task(\n",
        "        [\"hubert_base.pt\"],\n",
        "        suffix=\"\",\n",
        "    )\n",
        "    hubert_model = models[0]\n",
        "    hubert_model = hubert_model.to(device)\n",
        "    if is_half:\n",
        "        hubert_model = hubert_model.half()\n",
        "    else:\n",
        "        hubert_model = hubert_model.float()\n",
        "    hubert_model.eval()\n",
        "\n",
        "def change_to_tts_mode(tts_mode):\n",
        "    if tts_mode:\n",
        "        return gr.Audio.update(visible=False), gr.Textbox.update(visible=True), gr.Dropdown.update(visible=True)\n",
        "    else:\n",
        "        return gr.Audio.update(visible=True), gr.Textbox.update(visible=False), gr.Dropdown.update(visible=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--api', action=\"store_true\", default=False)\n",
        "    parser.add_argument(\"--share\", action=\"store_true\", default=False, help=\"share gradio app\")\n",
        "    parser.add_argument(\"--files\", action=\"store_true\", default=False, help=\"load audio from path\")\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    load_hubert()\n",
        "    models = []\n",
        "    tts_voice_list = asyncio.get_event_loop().run_until_complete(edge_tts.list_voices())\n",
        "    voices = [f\"{v['ShortName']}-{v['Gender']}\" for v in tts_voice_list]\n",
        "    with open(\"weights/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        models_info = json.load(f)\n",
        "    for name, info in models_info.items():\n",
        "        if not info['enable']:\n",
        "            continue\n",
        "        title = info['title']\n",
        "        author = info.get(\"author\", None)\n",
        "        cover = f\"weights/{name}/{info['cover']}\"\n",
        "        index = f\"weights/{name}/{info['feature_retrieval_library']}\"\n",
        "        npy = f\"weights/{name}/{info['feature_file']}\"\n",
        "        cpt = torch.load(f\"weights/{name}/{name}.pth\", map_location=\"cpu\")\n",
        "        tgt_sr = cpt[\"config\"][-1]\n",
        "        cpt[\"config\"][-3] = cpt[\"weight\"][\"emb_g.weight\"].shape[0]  # n_spk\n",
        "        if_f0 = cpt.get(\"f0\", 1)\n",
        "        if if_f0 == 1:\n",
        "            net_g = SynthesizerTrnMs256NSFsid(*cpt[\"config\"], is_half=is_half)\n",
        "        else:\n",
        "            net_g = SynthesizerTrnMs256NSFsid_nono(*cpt[\"config\"])\n",
        "        del net_g.enc_q\n",
        "        print(net_g.load_state_dict(cpt[\"weight\"], strict=False))  # ‰∏çÂä†Ëøô‰∏ÄË°åÊ∏Ö‰∏çÂπ≤ÂáÄ, ÁúüÂ•áËë©\n",
        "        net_g.eval().to(device)\n",
        "        if is_half:\n",
        "            net_g = net_g.half()\n",
        "        else:\n",
        "            net_g = net_g.float()\n",
        "        vc = VC(tgt_sr, device, is_half)\n",
        "        models.append((name, title, author, cover, create_vc_fn(tgt_sr, net_g, vc, if_f0, index, npy)))\n",
        "    with gr.Blocks() as app:\n",
        "        gr.Markdown(\n",
        "            \"# <center> Hololive RVC Models\\n\"\n",
        "            \"## <center> The input audio should be clean and pure voice without background music.\\n\"\n",
        "            \"[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/megaaziib)\\n\\n\"\n",
        "        )\n",
        "        with gr.Tabs():\n",
        "            for (name, title, author, cover, vc_fn) in models:\n",
        "                with gr.TabItem(name):\n",
        "                    with gr.Row():\n",
        "                        gr.Markdown(\n",
        "                            '<div align=\"center\">'\n",
        "                            f'<div>{title}</div>\\n'+\n",
        "                            (f'<div>Model author: {author}</div>' if author else \"\")+\n",
        "                            (f'<img style=\"width:auto;height:300px;\" src=\"file/{cover}\">' if cover else \"\")+\n",
        "                            '</div>'\n",
        "                        )\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            if args.files:\n",
        "                                vc_input = gr.Textbox(label=\"Input audio path\")\n",
        "                            else:\n",
        "                                vc_input = gr.Audio(label=\"Input audio\"+' (less than 11 minutes)' if limitation else '')\n",
        "                            vc_transpose = gr.Number(label=\"Transpose\", value=0)\n",
        "                            vc_f0method = gr.Radio(\n",
        "                                label=\"Pitch extraction algorithm, PM is fast but Harvest is better for low frequencies\",\n",
        "                                choices=[\"pm\", \"harvest\"],\n",
        "                                value=\"pm\",\n",
        "                                interactive=True,\n",
        "                            )\n",
        "                            vc_index_ratio = gr.Slider(\n",
        "                                minimum=0,\n",
        "                                maximum=1,\n",
        "                                label=\"Retrieval feature ratio\",\n",
        "                                value=0.6,\n",
        "                                interactive=True,\n",
        "                            )\n",
        "                            tts_mode = gr.Checkbox(label=\"tts (use edge-tts as input)\", value=False)\n",
        "                            tts_text = gr.Textbox(visible=False,label=\"TTS text (1200 words limitation)\" if limitation else \"TTS text\")\n",
        "                            tts_voice = gr.Dropdown(label=\"Edge-tts speaker\", choices=voices, visible=False, allow_custom_value=False, value=\"en-US-AnaNeural-Female\")\n",
        "                            vc_submit = gr.Button(\"Generate\", variant=\"primary\")\n",
        "                        with gr.Column():\n",
        "                            vc_output1 = gr.Textbox(label=\"Output Message\")\n",
        "                            vc_output2 = gr.Audio(label=\"Output Audio\")\n",
        "                vc_submit.click(vc_fn, [vc_input, vc_transpose, vc_f0method, vc_index_ratio, tts_mode, tts_text, tts_voice], [vc_output1, vc_output2])\n",
        "                tts_mode.change(change_to_tts_mode, [tts_mode], [vc_input, tts_text, tts_voice])\n",
        "        app.queue(concurrency_count=1, max_size=20, api_open=args.api).launch(share=args.share)\n",
        "     "
      ],
      "metadata": {
        "id": "JSxrQWyvJg8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the app.py to execute/run the Gradio app"
      ],
      "metadata": {
        "id": "JY5z6CCBFw1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python app.py"
      ],
      "metadata": {
        "id": "H7qo-6AWFbLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a55L_QRzM0c9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}